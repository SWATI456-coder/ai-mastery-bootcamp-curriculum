{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Notes: Advanced Pandas, NumPy & Functional Programming for ML\n",
    "\n",
    "**LogicMojo AI/ML Bootcamp – Part 4**  \n",
    "Theory → example format.\n",
    "\n",
    "## Topics\n",
    "1. **Functional Programming**: Lambda, Map, Filter, Reduce\n",
    "2. **Pandas Apply & Map** (DataFrames/Series)\n",
    "3. **Advanced Pandas**: GroupBy, Agg vs Transform, Merge, Text, Time, One-Hot\n",
    "4. **NumPy for ML**: Arrays, Shape, Broadcasting, Boolean Indexing, Dot Product\n",
    "5. **Data Preprocessing**: Binning, Encoding, Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 1: FUNCTIONAL PROGRAMMING\n",
    "\n",
    "## 1.1 Lambda Functions\n",
    "\n",
    "### Theory\n",
    "- **Lambda** = Small anonymous function: `lambda arguments: expression`.\n",
    "- Use for short, one-off operations (no `def` or `return`).\n",
    "- Often used with `map`, `filter`, `sorted(key=...)`, and pandas `.apply()`.\n",
    "- Limited to a single expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Lambda vs normal function\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "square_lambda = lambda x: x ** 2\n",
    "print(square(5), square_lambda(5))\n",
    "\n",
    "# Sorting by custom key\n",
    "pairs = [(1, 'one'), (3, 'three'), (2, 'two')]\n",
    "pairs.sort(key=lambda x: x[1])  # Sort by string\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Map, Filter, Reduce\n",
    "\n",
    "### Theory\n",
    "- **map(function, iterable)** → Apply function to every item; returns an iterator.\n",
    "- **filter(function, iterable)** → Keep only items where function is True.\n",
    "- **reduce(function, iterable [, initial])** → Combine all items into one value (e.g. product, sum).\n",
    "- Use `list()` on map/filter to get a list. Reduce returns a single value.\n",
    "- Essential for data cleaning and pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Map, Filter, Reduce\n",
    "numbers = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Map: square every number\n",
    "squared = list(map(lambda x: x**2, numbers))\n",
    "print(\"Map (squared):\", squared)\n",
    "\n",
    "# Filter: keep even numbers\n",
    "evens = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "print(\"Filter (evens):\", evens)\n",
    "\n",
    "# Reduce: product of all numbers\n",
    "product = reduce(lambda x, y: x * y, numbers)\n",
    "print(\"Reduce (product):\", product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Pandas Apply & Map\n",
    "\n",
    "### Theory\n",
    "- **Series.map(function)** → Element-wise mapping (substitutions, lookups).\n",
    "- **Series.apply(function)** → Element-wise; can use lambdas or multi-line logic.\n",
    "- **DataFrame.apply(function, axis=0/1)** → Apply along rows (axis=1) or columns (axis=0).\n",
    "- `.map()` is for Series only; `.apply()` works on Series and DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Pandas apply and map\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Income': [50000, 60000, 55000],\n",
    "    'Department': ['IT', 'HR', 'IT']\n",
    "})\n",
    "\n",
    "# .map() – element-wise substitution (Series only)\n",
    "df['Dept_Code'] = df['Department'].map({'IT': 1, 'HR': 2})\n",
    "\n",
    "# .apply() – custom function per row/column\n",
    "def tax_calc(income):\n",
    "    return income * 0.3 if income > 55000 else income * 0.2\n",
    "\n",
    "df['Tax'] = df['Income'].apply(tax_calc)\n",
    "df['Net_Income'] = df['Income'].apply(lambda x: x * 0.8)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 2: ADVANCED PANDAS\n",
    "\n",
    "## 2.1 GroupBy & Aggregation\n",
    "\n",
    "### Theory\n",
    "- **groupby(column)** groups rows by unique values; then apply aggregations.\n",
    "- **agg()** lets you specify different aggregations per column: sum, mean, min, max, count.\n",
    "- **Multiple columns**: `groupby(['A','B'])` and `.agg({col: [list of funcs]})`.\n",
    "- **unstack()** turns an index level into columns (long → wide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: GroupBy and aggregation\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame({\n",
    "    'Date': pd.date_range('2023-01-01', periods=100),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'Product': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Sales': np.random.randint(100, 1000, 100)\n",
    "})\n",
    "\n",
    "# Total sales per region\n",
    "region_sales = df.groupby('Region')['Sales'].sum()\n",
    "print(\"Sales by Region:\", region_sales)\n",
    "\n",
    "# Multiple aggregations per product\n",
    "product_stats = df.groupby('Product')['Sales'].agg(['mean', 'min', 'max', 'count'])\n",
    "print(\"\\nProduct stats:\", product_stats)\n",
    "\n",
    "# Group by two columns, then unstack\n",
    "summary = df.groupby(['Region', 'Product'])['Sales'].mean().unstack()\n",
    "print(\"\\nRegion vs Product (mean):\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Agg vs Transform\n",
    "\n",
    "### Theory\n",
    "- **Aggregation**: Many rows → one row per group (e.g. sum, mean).\n",
    "- **Transform**: Same shape as original; each row gets a group-level value (e.g. group sum attached to every row).\n",
    "- Use **transform** when you need “percent of group total” or “deviation from group mean” while keeping one row per observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Agg vs Transform\n",
    "df_sales = pd.DataFrame({\n",
    "    'Store': ['A', 'A', 'B', 'B', 'B'],\n",
    "    'Sales': [100, 200, 150, 250, 100]\n",
    "})\n",
    "\n",
    "# Agg: one row per group\n",
    "agg_result = df_sales.groupby('Store')['Sales'].agg('sum')\n",
    "print(\"Agg (sum per store):\", agg_result)\n",
    "\n",
    "# Transform: group sum repeated for each row\n",
    "df_sales['Store_Total'] = df_sales.groupby('Store')['Sales'].transform('sum')\n",
    "df_sales['Pct_of_Store'] = (df_sales['Sales'] / df_sales['Store_Total']) * 100\n",
    "print(\"\\nWith transform:\", df_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3 Merging & Joining\n",
    "\n",
    "### Theory\n",
    "- **pd.merge(left, right, on='col', how='inner'|'left'|'right'|'outer')**.\n",
    "- **inner**: Only matching keys in both.\n",
    "- **left**: All rows from left; match from right where possible (NaN if no match).\n",
    "- **right**: All from right.\n",
    "- **outer**: All keys from both; NaN where no match.\n",
    "- For ML we often use **left** to keep all events and fill missing with NaN or default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Merge (inner vs left)\n",
    "users = pd.DataFrame({'UserID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "trans = pd.DataFrame({'TxID': [101, 102, 103], 'UserID': [1, 2, 5], 'Amount': [500, 200, 100]})\n",
    "\n",
    "inner = pd.merge(trans, users, on='UserID', how='inner')\n",
    "print(\"Inner (only matches):\", inner)\n",
    "\n",
    "left = pd.merge(trans, users, on='UserID', how='left')\n",
    "print(\"\\nLeft (all transactions):\", left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4 Text Processing (str accessor)\n",
    "\n",
    "### Theory\n",
    "- Use **Series.str** for string methods: `.str.strip()`, `.str.title()`, `.str.contains()`, `.str.split()`.\n",
    "- Enables cleaning and feature extraction from text (e.g. extract domain, first/last name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Text with .str\n",
    "text_df = pd.DataFrame({\n",
    "    'Name': ['  john doe ', 'jane smith', 'bob johnson'],\n",
    "    'Email': ['john@gmail.com', 'jane@test.com', 'bob@yahoo.com']\n",
    "})\n",
    "text_df['Name_Clean'] = text_df['Name'].str.strip().str.title()\n",
    "text_df['Is_Gmail'] = text_df['Email'].str.contains('gmail')\n",
    "text_df[['First', 'Last']] = text_df['Name_Clean'].str.split(' ', expand=True)\n",
    "print(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.5 Time Series Features\n",
    "\n",
    "### Theory\n",
    "- Use **pd.to_datetime()** so the column is datetime.\n",
    "- **.dt** accessor: `.dt.month`, `.dt.dayofweek`, `.dt.day`, etc.\n",
    "- **rolling(window=n)** for moving average or other rolling stats.\n",
    "- ML models need numeric features; extract month, day of week, is_weekend, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Time features and rolling\n",
    "df = pd.DataFrame({\n",
    "    'Date': pd.date_range('2023-01-01', periods=10, freq='D'),\n",
    "    'Sales': [100, 120, 90, 150, 130, 110, 140, 160, 120, 180]\n",
    "})\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['Is_Weekend'] = df['Date'].dt.dayofweek > 4\n",
    "df['Sales_3Day_Avg'] = df['Sales'].rolling(window=3).mean()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.6 One-Hot Encoding\n",
    "\n",
    "### Theory\n",
    "- ML models need numbers; categories like \"Red\", \"Blue\" must be encoded.\n",
    "- **pd.get_dummies(df, columns=[...])** creates binary columns per category.\n",
    "- **drop_first=True** avoids multicollinearity in linear models (one column is redundant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: One-hot encoding\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Blue'], 'Price': [10, 20, 15, 10, 20]})\n",
    "encoded = pd.get_dummies(data, columns=['Color'], drop_first=False)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 3: NUMPY FOR ML\n",
    "\n",
    "## 3.1 Creating Arrays\n",
    "\n",
    "### Theory\n",
    "- **np.array(list)** converts list to array.\n",
    "- **np.arange(start, stop, step)** like range but returns array.\n",
    "- **np.zeros(shape)**, **np.ones(shape)** for initialization.\n",
    "- **np.random.rand(shape)** uniform [0,1); **np.random.randn(shape)** standard normal.\n",
    "- ML libraries expect NumPy arrays; they are fast and support vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Array creation\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(\"Array:\", arr)\n",
    "print(\"arange:\", np.arange(0, 10, 2))\n",
    "print(\"zeros 3x3:\\n\", np.zeros((3, 3)))\n",
    "print(\"ones 2x4:\\n\", np.ones((2, 4)))\n",
    "np.random.seed(42)\n",
    "print(\"rand (0-1):\\n\", np.random.rand(2, 3))\n",
    "print(\"randn (normal):\\n\", np.random.randn(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Shape and Reshape\n",
    "\n",
    "### Theory\n",
    "- **.shape** gives dimensions (rows, cols) or (n,) for 1D.\n",
    "- **.reshape(rows, cols)** changes layout; total size must stay the same.\n",
    "- **reshape(-1, n)** means “n columns, compute rows automatically”.\n",
    "- **.flatten()** turns matrix into 1D. Critical for avoiding shape errors in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Shape and reshape\n",
    "arr = np.arange(12)\n",
    "print(\"1D:\", arr, \"shape:\", arr.shape)\n",
    "arr_2d = arr.reshape(3, 4)\n",
    "print(\"2D (3x4):\\n\", arr_2d)\n",
    "arr_auto = arr.reshape(-1, 4)\n",
    "print(\"reshape(-1, 4):\\n\", arr_auto)\n",
    "print(\"flatten:\", arr_2d.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Broadcasting & Vectorization\n",
    "\n",
    "### Theory\n",
    "- **Vectorization**: Operations on whole arrays without Python loops (much faster).\n",
    "- **Broadcasting**: NumPy expands smaller dimensions so shapes match (e.g. add (3,) to (2,3)).\n",
    "- Rule: dimensions are compatible if they are equal or one of them is 1.\n",
    "- Example: adding a bias vector to a batch of samples (matrix + vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Broadcasting\n",
    "data = np.array([1, 2, 3, 4])\n",
    "print(\"Plus 10:\", data + 10)\n",
    "print(\"Squared:\", data ** 2)\n",
    "\n",
    "matrix = np.array([[10, 20, 30], [40, 50, 60]])  # (2, 3)\n",
    "bias = np.array([1, 2, 3])                        # (3,)\n",
    "result = matrix + bias  # bias broadcast to each row\n",
    "print(\"Matrix + bias:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.4 Boolean Indexing\n",
    "\n",
    "### Theory\n",
    "- Create a boolean array (mask) from a condition: `arr > 0`.\n",
    "- Use mask to select: `arr[mask]` or `arr[arr > 0]`.\n",
    "- Use for filtering outliers or selecting classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Boolean indexing\n",
    "data = np.array([10, -5, 30, -2, 50, 0])\n",
    "mask = data > 0\n",
    "print(\"Mask:\", mask)\n",
    "print(\"Positive:\", data[mask])\n",
    "\n",
    "# Clip: cap values\n",
    "data_clip = data.copy()\n",
    "data_clip[data_clip > 40] = 40\n",
    "print(\"Clipped:\", data_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.5 Dot Product (Linear Algebra)\n",
    "\n",
    "### Theory\n",
    "- **y = Wx + b** is the core of neural layers: matrix-vector or matrix-matrix multiply.\n",
    "- **np.dot(a, b)** or **a @ b** for matrix multiplication.\n",
    "- Shape rule: (m, n) @ (n, p) → (m, p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Dot product (like one layer)\n",
    "X = np.array([0.5, 0.1, -0.2])  # 1 sample, 3 features\n",
    "W = np.array([[1.0, 0.5], [-0.5, 0.2], [0.1, -0.1]])  # 3 in, 2 out\n",
    "output = X @ W  # (3,) @ (3, 2) -> (2,)\n",
    "print(\"X:\", X)\n",
    "print(\"W:\\n\", W)\n",
    "print(\"Output (X @ W):\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 4: DATA PREPROCESSING\n",
    "\n",
    "## 4.1 Binning (pd.cut, pd.qcut)\n",
    "\n",
    "### Theory\n",
    "- **pd.cut(series, bins=[...], labels=[...])** – fixed bin edges (e.g. age groups).\n",
    "- **pd.qcut(series, q=n, labels=[...])** – quantile-based; roughly equal counts per bin.\n",
    "- Turns continuous variables into categories for analysis or encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Binning\n",
    "ages = pd.Series([15, 25, 45, 70, 22, 55, 18, 80])\n",
    "bins = [0, 18, 35, 60, 100]\n",
    "labels = ['Child', 'Young', 'Adult', 'Senior']\n",
    "ages_cut = pd.cut(ages, bins=bins, labels=labels)\n",
    "print(\"pd.cut:\", ages_cut)\n",
    "\n",
    "incomes = pd.Series([20000, 50000, 80000, 35000, 90000, 45000])\n",
    "incomes_q = pd.qcut(incomes, q=3, labels=['Low', 'Mid', 'High'])\n",
    "print(\"pd.qcut:\", incomes_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2 Label & Frequency Encoding\n",
    "\n",
    "### Theory\n",
    "- **Label encoding**: Category → integer (e.g. Red=0, Blue=1). Use `.astype('category').cat.codes` or a mapping.\n",
    "- **Frequency encoding**: Replace category with its count or proportion in the dataset; good for high-cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Label and frequency encoding\n",
    "df = pd.DataFrame({'City': ['NY', 'Paris', 'London', 'Paris', 'NY'], 'Price': [100, 200, 150, 220, 110]})\n",
    "df['City_Label'] = df['City'].astype('category').cat.codes\n",
    "freq_map = df['City'].value_counts(normalize=True)\n",
    "df['City_Freq'] = df['City'].map(freq_map)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3 Outlier Handling\n",
    "\n",
    "### Theory\n",
    "- **Clipping (capping)**: Restrict values to a range, e.g. 5th–95th percentile: `series.clip(lower, upper)`.\n",
    "- **IQR removal**: Values outside Q1 − 1.5×IQR or Q3 + 1.5×IQR are often treated as outliers (remove or cap).\n",
    "- Outliers can hurt linear models; clipping keeps shape while limiting impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: Outliers – clip and IQR\n",
    "data = pd.Series([10, 12, 11, 14, 12, 11, 10, 1000])\n",
    "print(\"Original mean:\", data.mean())\n",
    "\n",
    "lower, upper = data.quantile(0.05), data.quantile(0.95)\n",
    "clipped = data.clip(lower=lower, upper=upper)\n",
    "print(\"After clip:\", clipped.values, \"mean:\", clipped.mean())\n",
    "\n",
    "Q1, Q3 = data.quantile(0.25), data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "fence = 1.5 * IQR\n",
    "filtered = data[(data >= Q1 - fence) & (data <= Q3 + fence)]\n",
    "print(\"After IQR filter:\", filtered.values, \"mean:\", filtered.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary – Quick Reference\n",
    "\n",
    "| Topic | Key idea | Example |\n",
    "|-------|----------|--------|\n",
    "| Lambda | Anonymous function | `lambda x: x**2` |\n",
    "| Map | Apply to each | `list(map(f, lst))` |\n",
    "| Filter | Keep where True | `list(filter(f, lst))` |\n",
    "| Reduce | Single value | `reduce(lambda x,y: x*y, lst)` |\n",
    "| apply/map | Pandas element-wise | `df['col'].apply(f)` |\n",
    "| groupby | Group + agg/transform | `df.groupby('A')['B'].sum()` |\n",
    "| merge | Join tables | `pd.merge(left, right, on=..., how='left')` |\n",
    "| NumPy shape | Reshape for ML | `arr.reshape(-1, n)` |\n",
    "| Broadcasting | Array + scalar/vector | `matrix + bias` |\n",
    "| Dot product | Weights × inputs | `X @ W` |\n",
    "| Binning | Continuous → categories | `pd.cut`, `pd.qcut` |\n",
    "| Outliers | Clip or IQR filter | `series.clip(lower, upper)` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
