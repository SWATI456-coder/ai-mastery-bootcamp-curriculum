{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6b08fa",
   "metadata": {},
   "source": [
    "# üöÄ Linear Regression \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcaa3e",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Step 0: Importing Our Tools\n",
    "\n",
    "Before we build anything, we need the right tools. In Python, we don't write everything from scratch‚Äîwe import libraries created by smart people around the world!\n",
    "\n",
    "### üßë‚Äçüè´ Modules :\n",
    "*   `numpy` (Numerical Python): Think of this as a super-powered calculator. It handles complex math and large grids of numbers (arrays/matrices) extremely fast.\n",
    "*   `pandas`: This is basically Excel on steroids. It lets us load data, manipulate columns/rows, and view it nicely in a table (DataFrame).\n",
    "*   `matplotlib.pyplot`: This is our paintbrush. We use it to draw charts and graphs so we can *see* our data and errors visually.\n",
    "*   `sklearn` (Scikit-Learn): The ultimate Machine Learning toolbox! It contains everything we need:\n",
    "    *   `load_diabetes`: A built-in dataset we can use instantly.\n",
    "    *   `train_test_split`: A tool to randomly chop our data into \"study\" and \"exam\" sets.\n",
    "    *   `mean_absolute_error, mean_squared_error, r2_score`: Our \"grading tools\" to see how well the model performed.\n",
    "    *   `LinearRegression`: The actual ML algorithm we will train.\n",
    "    *   `RidgeCV, LassoCV`: Advanced forms of linear regression to stop the model from memorizing too much (Regularization).\n",
    "    *   `StandardScaler`: A tool to make sure all numerical features are on the same \"scale\" (e.g., converting heights in cm and weights in kg into a standardized format).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd267ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn datasets and tools\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set plot style for better visuals\n",
    "try:\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "except OSError:\n",
    "    plt.style.use(\"ggplot\")\n",
    "\n",
    "# Convenience: show more columns in dataframe printing\n",
    "pd.set_option(\"display.max_columns\", 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5fb56",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Introduction to the Problem & The Data\n",
    "\n",
    "**üí° Concept:** Machine learning is about finding patterns in data to predict the future. Here, we are trying to predict a **continuous number** (disease progression of diabetes). This makes it a **Regression** problem, not a Classification problem.\n",
    "\n",
    "Let's load our data and take a look! We will use the built-in Scikit-Learn **Diabetes dataset**.\n",
    "\n",
    "### üìä Understanding the Columns (Features)\n",
    "The dataset contains 442 patients, and for each patient, we have 10 baseline variables (features):\n",
    "1.  **age**: Age (in years)\n",
    "2.  **sex**: Sex\n",
    "3.  **bmi**: Body mass index\n",
    "4.  **bp**: Average blood pressure\n",
    "5.  **s1 (tc)**: Total serum cholesterol\n",
    "6.  **s2 (ldl)**: Low-density lipoproteins\n",
    "7.  **s3 (hdl)**: High-density lipoproteins\n",
    "8.  **s4 (tch)**: Total cholesterol / HDL\n",
    "9.  **s5 (ltg)**: Log of serum triglycerides level\n",
    "10. **s6 (glu)**: Blood sugar level\n",
    "\n",
    "**Target Variable (What we want to predict!):**\n",
    "*   **Target**: A quantitative measure of disease progression one year after baseline. (A higher number means the diabetes got worse).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3a2f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 442 rows (patients) and 10 features (columns).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the built-in Diabetes dataset\n",
    "data = load_diabetes(as_frame=True)\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X_df = data.data.copy()\n",
    "y = data.target.copy()\n",
    "\n",
    "# Combine for easier EDA\n",
    "df = X_df.copy()\n",
    "df[\"target\"] = y\n",
    "\n",
    "print(f\"Dataset has {df.shape[0]} rows (patients) and {X_df.shape[1]} features (columns).\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59727121",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 2Ô∏è‚É£ Train/Test Split & Baseline Model\n",
    "\n",
    "**üí° Concept:** We never test a model on the exact same data it practiced with! If we do, it might just memorize the answers. We split our data into **Training** (practice) and **Testing** (final evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f709bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 353 samples. Testing on 89 samples.\n"
     ]
    }
   ],
   "source": [
    "# Split the data! 80% for training (homework), 20% for testing (exam)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training on {X_train.shape[0]} samples. Testing on {X_test.shape[0]} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43948f26",
   "metadata": {},
   "source": [
    "### The Baseline (The \"Dumb\" Model)\n",
    "\n",
    "**üí° Concept:** Before we do fancy AI, what if we just guessed the **average** disease progression for EVERY patient? We call this our baseline. If our AI cannot beat the average guess, our AI is useless!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ca9ba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the average (153.7) gives a Mean Absolute Error (MAE) of: 64.01\n",
      "Our ML model MUST get an error lower than this to be considered useful!\n"
     ]
    }
   ],
   "source": [
    "# Guess the average of the training set for every single test patient\n",
    "mean_guess = y_train.mean()\n",
    "baseline_predictions = np.full(shape=y_test.shape, fill_value=mean_guess)\n",
    "\n",
    "baseline_mae = mean_absolute_error(y_test, baseline_predictions)\n",
    "\n",
    "print(f\"Guessing the average ({mean_guess:.1f}) gives a Mean Absolute Error (MAE) of: {baseline_mae:.2f}\")\n",
    "print(\"Our ML model MUST get an error lower than this to be considered useful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247200e9",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Building the ML Model (Linear Regression)\n",
    "\n",
    "**üí° Concept:** Linear regression tries to draw the \"Best Fit Line\" through our data. Mathematically, it's finding the weights (w) for each feature.\n",
    "Equation: `Target = (w1 * age) + (w2 * bmi) + (w3 * bp) ... + intercept`\n",
    "\n",
    "**ü§î Frequent Doubt:**\n",
    "> *\"How does the computer know what the 'w' (weights) are? Does it just guess?\"*\n",
    "> **Explanation:** \"Initially, yes! It starts with random guesses (or zeros). Then it looks at how wrong its predictions are (the Error), and mathematically calculates how to adjust those weights to make the error smaller. It repeats this until it finds the best possible weights. \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c478e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• ML Model MAE: 42.79 (Beat the baseline of 64.01!)\n",
      "üî• ML Model RMSE: 2900.19\n",
      "üî• ML Model R-Squared: 0.45\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# 2. Train the model (Model learns the weights here!)\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions on the Test set (The Final Exam)\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# 4. Evaluate how well it did\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"üî• ML Model MAE: {mae:.2f} (Beat the baseline of {baseline_mae:.2f}!)\")\n",
    "print(f\"üî• ML Model RMSE: {rmse:.2f}\")\n",
    "print(f\"üî• ML Model R-Squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4843d",
   "metadata": {},
   "source": [
    "### Evaluating Performance (Metrics)\n",
    "\n",
    "\n",
    "**üí° Concept:** \n",
    "- **MAE (Mean Absolute Error):** Easy to explain. The simple average of our errors.\n",
    "- **RMSE (Root Mean Squared Error):** Punishes large errors heavily (because errors are squared before averaging). Useful if being slightly wrong is okay, but being *very* wrong is disastrous.\n",
    "- **R¬≤ (R-Squared):** Percentage of variance explained. 1.0 is a perfect score! 0 is as bad as just guessing the average baseline. (Here it's 0.45, meaning our features explain 45% of what's happening. The rest is random noise, or maybe we need better features like diet/genetics to get a higher score).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d76e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most impactful features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1</td>\n",
       "      <td>-931.488846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s5</td>\n",
       "      <td>736.198859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmi</td>\n",
       "      <td>542.428759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s2</td>\n",
       "      <td>518.062277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bp</td>\n",
       "      <td>347.703844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature      Weight\n",
       "4      s1 -931.488846\n",
       "8      s5  736.198859\n",
       "2     bmi  542.428759\n",
       "5      s2  518.062277\n",
       "3      bp  347.703844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's peek at the \"Weights\" the model learned\n",
    "weights_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Weight\": lin_reg.coef_\n",
    "}).sort_values(by=\"Weight\", key=abs, ascending=False)\n",
    "\n",
    "print(\"Top 5 most impactful features:\")\n",
    "display(weights_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33af953",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Regularization: Keeping the Model in Check (Ridge & Lasso)\n",
    "\n",
    "**üí° Concept:** Sometimes models memorize the training data too well (Overfitting) and assign crazy high weights to certain features. **Regularization** acts as a penalty fee. The model pays a fine if its weights get too big.\n",
    "\n",
    "\n",
    "Let's test this! We'll see if Lasso automatically sets some of our 10 features' weights to exactly 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fce59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso set 3 out of 10 feature weights to EXACTLY Zero!\n",
      "It automatically did Feature Selection for us! üé©‚ú®\n"
     ]
    }
   ],
   "source": [
    "# We use CV (Cross-Validation) versions so Scikit-Learn automatically finds the best \"fine\" (alpha/lambda) to charge the model.\n",
    "alphas = np.logspace(-4, 4, 100)\n",
    "\n",
    "# Ridge (L2)\n",
    "ridge_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()), # Always scale before regularizing!\n",
    "    (\"ridge\", RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "# Lasso (L1)\n",
    "lasso_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso\", LassoCV(alphas=alphas, cv=5, max_iter=20000))\n",
    "])\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Compare how many features Lasso \"kicked out\" (set weight to 0)\n",
    "lasso_weights = lasso_model.named_steps[\"lasso\"].coef_\n",
    "zero_weights_count = sum(abs(lasso_weights) < 1e-7)\n",
    "\n",
    "print(f\"Lasso set {zero_weights_count} out of {X_train.shape[1]} feature weights to EXACTLY Zero!\")\n",
    "print(\"It automatically did Feature Selection for us! üé©‚ú®\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a78016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ecomm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
